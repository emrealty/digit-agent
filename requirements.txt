torch>=2.3.0
transformers>=4.50.0
accelerate>=0.29
pillow
rich

# GGUF (llama.cpp) seçeneği
llama-cpp-python>=0.2.73 ; extra == "gguf"
